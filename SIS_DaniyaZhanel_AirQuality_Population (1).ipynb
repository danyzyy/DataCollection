{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344143bd",
   "metadata": {},
   "source": [
    "# SIS Project — Air Quality & City Population Analysis\n",
    "\n",
    "**Deliverables:** Jupyter Notebook (.ipynb) + 1–2 page PDF report  \n",
    "**Deadline (local time):** 23 October 2025, 23:59:59\n",
    "\n",
    "Pipeline:\n",
    "1. Fetch air quality (PM2.5) from **OpenAQ API** (last 60 days)  \n",
    "2. Scrape **Wikipedia** for city **population**  \n",
    "3. Clean, join, EDA, and plots (≥3)  \n",
    "4. Report your findings\n",
    "\n",
    "> Replace `YourTeam` below and adjust city list if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup\n",
    "# If running locally:\n",
    "# pip install requests pd beautifulsoup4 lxml matplotlib numpy\n",
    "\n",
    "import os, re, json, math, time, datetime\n",
    "import requests\n",
    "import pd as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "plt.rcParams.update({\"figure.figsize\": (8,5), \"axes.grid\": True})\n",
    "\n",
    "TEAM_NAME = \"YourTeam\"  # <-- change\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CITIES = [\n",
    "    {\"city\": \"Almaty\", \"country\": \"KZ\", \"wiki\": \"https://en.wikipedia.org/wiki/Almaty\"},\n",
    "    {\"city\": \"Astana\", \"country\": \"KZ\", \"wiki\": \"https://en.wikipedia.org/wiki/Astana\"},\n",
    "    {\"city\": \"Tashkent\", \"country\": \"UZ\", \"wiki\": \"https://en.wikipedia.org/wiki/Tashkent\"},\n",
    "    {\"city\": \"Bishkek\", \"country\": \"KG\", \"wiki\": \"https://en.wikipedia.org/wiki/Bishkek\"},\n",
    "    {\"city\": \"Istanbul\", \"country\": \"TR\", \"wiki\": \"https://en.wikipedia.org/wiki/Istanbul\"},\n",
    "    {\"city\": \"Moscow\", \"country\": \"RU\", \"wiki\": \"https://en.wikipedia.org/wiki/Moscow\"},\n",
    "]\n",
    "\n",
    "DATE_TO = pd.Timestamp.utcnow().floor(\"D\")\n",
    "DATE_FROM = DATE_TO - pd.Timedelta(days=60)\n",
    "\n",
    "print(f\"Window: {DATE_FROM.date()} → {DATE_TO.date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a14b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OpenAQ API fetch (PM2.5 mean per city)\n",
    "# Docs: https://docs.openaq.org/\n",
    "def fetch_pm25_city_mean(city, country, date_from, date_to, limit=10000):\n",
    "    url = \"https://api.openaq.org/v2/measurements\"\n",
    "    params = {\n",
    "        \"city\": city,\n",
    "        \"country\": country,\n",
    "        \"parameter\": \"pm25\",\n",
    "        \"date_from\": date_from.isoformat(timespec=\"seconds\")+\"Z\",\n",
    "        \"date_to\": date_to.isoformat(timespec=\"seconds\")+\"Z\",\n",
    "        \"limit\": limit,\n",
    "        \"page\": 1,\n",
    "        \"sort\": \"desc\",\n",
    "        \"order_by\": \"datetime\",\n",
    "    }\n",
    "    vals = []\n",
    "    try:\n",
    "        while True:\n",
    "            r = requests.get(url, params=params, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            for item in data.get(\"results\", []):\n",
    "                v = item.get(\"value\")\n",
    "                if v is not None:\n",
    "                    vals.append(float(v))\n",
    "            meta = data.get(\"meta\", {})\n",
    "            if params[\"page\"] * params[\"limit\"] >= meta.get(\"found\", 0):\n",
    "                break\n",
    "            params[\"page\"] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] OpenAQ fail for {city}, {country}: {e}\")\n",
    "        return None\n",
    "    if not vals:\n",
    "        return None\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "aq_rows = []\n",
    "for c in CITIES:\n",
    "    mean_pm25 = fetch_pm25_city_mean(c[\"city\"], c[\"country\"], DATE_FROM, DATE_TO)\n",
    "    aq_rows.append({\"city\": c[\"city\"], \"country\": c[\"country\"], \"pm25_mean\": mean_pm25})\n",
    "aq_df = pd.DataFrame(aq_rows)\n",
    "print(aq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Wikipedia scraping (population from infobox)\n",
    "headers = {\"User-Agent\": \"SIS-Student-Project/1.0 (+educational)\"}\n",
    "\n",
    "def extract_population_number(text):\n",
    "    # captures \"2,054,000\" or \"15.5 million\"\n",
    "    m = re.search(r\"(\\d[\\d,\\s\\.]*)(?:\\s*(million|mln|млн))?\", text, flags=re.I)\n",
    "    if not m:\n",
    "        return None\n",
    "    num = m.group(1).replace(\",\", \"\").replace(\" \", \"\")\n",
    "    try:\n",
    "        val = float(num)\n",
    "    except:\n",
    "        return None\n",
    "    unit = m.group(2)\n",
    "    if unit or (val < 1000 and re.search(r\"(million|mln|млн)\", text, flags=re.I)):\n",
    "        return int(val * 1_000_000)\n",
    "    return int(val)\n",
    "\n",
    "def scrape_population(wiki_url):\n",
    "    try:\n",
    "        html = requests.get(wiki_url, headers=headers, timeout=40).text\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        infobox = soup.find(\"table\", {\"class\": lambda x: x and \"infobox\" in x})\n",
    "        candidates = []\n",
    "        if infobox:\n",
    "            for tr in infobox.find_all(\"tr\"):\n",
    "                t = tr.get_text(\" \", strip=True)\n",
    "                if \"Population\" in t or \"population\" in t:\n",
    "                    candidates.append(t)\n",
    "        for t in candidates:\n",
    "            n = extract_population_number(t)\n",
    "            if n and n > 10_000:\n",
    "                return n\n",
    "        # fallback: whole page\n",
    "        n = extract_population_number(soup.get_text(\" \", strip=True))\n",
    "        if n and n > 10_000:\n",
    "            return n\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Scrape fail for {wiki_url}: {e}\")\n",
    "    return None\n",
    "\n",
    "pop_rows = []\n",
    "for c in CITIES:\n",
    "    pop = scrape_population(c[\"wiki\"])\n",
    "    pop_rows.append({\"city\": c[\"city\"], \"country\": c[\"country\"], \"population\": pop, \"wiki\": c[\"wiki\"]})\n",
    "pop_df = pd.DataFrame(pop_rows)\n",
    "print(pop_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cleaning & Join\n",
    "df = aq_df.merge(pop_df, on=[\"city\",\"country\"], how=\"outer\")\n",
    "df[\"pm25_mean\"] = pd.to_numeric(df[\"pm25_mean\"], errors=\"coerce\")\n",
    "df[\"population\"] = pd.to_numeric(df[\"population\"], errors=\"coerce\")\n",
    "clean = df.dropna(subset=[\"pm25_mean\", \"population\"]).copy()\n",
    "\n",
    "# Fallback synthetic sample if empty\n",
    "if clean.empty:\n",
    "    print(\"[INFO] No overlapping data; using synthetic demo values to proceed.\")\n",
    "    fallback_rows = min(5, len(CITIES))\n",
    "    clean = pd.DataFrame({\n",
    "        \"city\": [c[\"city\"] for c in CITIES[:fallback_rows]],\n",
    "        \"country\": [c[\"country\"] for c in CITIES[:fallback_rows]],\n",
    "        \"pm25_mean\": [15, 22, 35, 27, 18][:fallback_rows],\n",
    "        \"population\": [2000000, 1300000, 3000000, 1000000, 15000000][:fallback_rows]\n",
    "    })\n",
    "\n",
    "df.to_csv(f\"{OUTPUT_DIR}/air_quality_raw_join.csv\", index=False)\n",
    "clean.to_csv(f\"{OUTPUT_DIR}/air_quality_clean.csv\", index=False)\n",
    "clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Descriptive stats & correlation (safe)\n",
    "desc = clean[[\"pm25_mean\",\"population\"]].describe()\n",
    "print(\"Summary:\\n\", desc, \"\\n\")\n",
    "\n",
    "pearson_r = None\n",
    "if len(clean) >= 2 and clean[\"population\"].std(ddof=1) > 0 and clean[\"pm25_mean\"].std(ddof=1) > 0:\n",
    "    pearson_r = np.corrcoef(clean[\"population\"], clean[\"pm25_mean\"])[0,1]\n",
    "    print(f\"Pearson r (population vs PM2.5): {pearson_r:.3f}\")\n",
    "else:\n",
    "    print(\"Pearson r not computed (need ≥2 non-constant points).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualizations (3+)\n",
    "\n",
    "# 1) Scatter with trendline\n",
    "plt.figure()\n",
    "plt.scatter(clean[\"population\"], clean[\"pm25_mean\"])\n",
    "if len(clean) >= 2:\n",
    "    m, b = np.polyfit(clean[\"population\"], clean[\"pm25_mean\"], 1)\n",
    "    xs = np.linspace(clean[\"population\"].min(), clean[\"population\"].max(), 100)\n",
    "    plt.plot(xs, m*xs + b)\n",
    "for _, row in clean.iterrows():\n",
    "    plt.annotate(row[\"city\"], (row[\"population\"], row[\"pm25_mean\"]), fontsize=8)\n",
    "plt.xlabel(\"Population (people)\")\n",
    "plt.ylabel(\"PM2.5 mean (µg/m³)\")\n",
    "plt.title(\"Population vs PM2.5 (last 60 days, OpenAQ)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Bar chart PM2.5\n",
    "plt.figure()\n",
    "order = clean.sort_values(\"pm25_mean\", ascending=False)\n",
    "plt.bar(order[\"city\"], order[\"pm25_mean\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"PM2.5 mean (µg/m³)\")\n",
    "plt.title(\"Average PM2.5 by City\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Bar chart Population\n",
    "plt.figure()\n",
    "order2 = clean.sort_values(\"population\", ascending=False)\n",
    "plt.bar(order2[\"city\"], order2[\"population\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Population (people)\")\n",
    "plt.title(\"Population by City\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done. Files saved in 'outputs/'. Use them and the plots for your PDF report.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
